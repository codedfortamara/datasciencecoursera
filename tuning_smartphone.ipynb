{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHqAYr7COo0F/l57LnkEF/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codedfortamara/datasciencecoursera/blob/main/tuning_smartphone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grJ0Ivky__aP",
        "outputId": "3adcfee8-326f-4df0-e853-fbc52ae79d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing configuration: Dropout Rate - 0.2, Learning Rate - 0.001\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6712 - loss: 0.8105 - val_accuracy: 0.9500 - val_loss: 0.1391\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9308 - loss: 0.1902 - val_accuracy: 0.9675 - val_loss: 0.0895\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9480 - loss: 0.1426 - val_accuracy: 0.9650 - val_loss: 0.0949\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9572 - loss: 0.1209 - val_accuracy: 0.9660 - val_loss: 0.0861\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9636 - loss: 0.1028 - val_accuracy: 0.9684 - val_loss: 0.0889\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9628 - loss: 0.0928 - val_accuracy: 0.9714 - val_loss: 0.0840\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9727 - loss: 0.0756 - val_accuracy: 0.9752 - val_loss: 0.0623\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9712 - loss: 0.0680 - val_accuracy: 0.9748 - val_loss: 0.0696\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.0701 - val_accuracy: 0.9728 - val_loss: 0.0628\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9759 - loss: 0.0603 - val_accuracy: 0.9684 - val_loss: 0.0808\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7780 - loss: 0.5607 - val_accuracy: 0.9563 - val_loss: 0.1230\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9635 - loss: 0.0933 - val_accuracy: 0.9655 - val_loss: 0.0867\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9724 - loss: 0.0695 - val_accuracy: 0.9680 - val_loss: 0.0720\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9725 - loss: 0.0653 - val_accuracy: 0.9714 - val_loss: 0.0697\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9829 - loss: 0.0457 - val_accuracy: 0.9626 - val_loss: 0.1164\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0424 - val_accuracy: 0.9762 - val_loss: 0.0590\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0317 - val_accuracy: 0.9791 - val_loss: 0.0525\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0306 - val_accuracy: 0.9830 - val_loss: 0.0548\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0302 - val_accuracy: 0.9767 - val_loss: 0.0712\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0361 - val_accuracy: 0.9752 - val_loss: 0.0685\n",
            "Dropout Model Validation Accuracy: 0.9684466123580933\n",
            "No Dropout Model Validation Accuracy: 0.9752427339553833\n",
            "Testing configuration: Dropout Rate - 0.2, Learning Rate - 0.002\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6778 - loss: 0.7525 - val_accuracy: 0.9369 - val_loss: 0.1589\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9263 - loss: 0.1912 - val_accuracy: 0.9505 - val_loss: 0.1353\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1440 - val_accuracy: 0.9621 - val_loss: 0.1046\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1246 - val_accuracy: 0.9539 - val_loss: 0.1034\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9662 - loss: 0.1061 - val_accuracy: 0.9553 - val_loss: 0.1161\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9672 - loss: 0.0883 - val_accuracy: 0.9718 - val_loss: 0.0703\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9686 - loss: 0.0786 - val_accuracy: 0.9709 - val_loss: 0.0720\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.0898 - val_accuracy: 0.9223 - val_loss: 0.2245\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9708 - loss: 0.0767 - val_accuracy: 0.9728 - val_loss: 0.0741\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9706 - loss: 0.0790 - val_accuracy: 0.9782 - val_loss: 0.0600\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8325 - loss: 0.3951 - val_accuracy: 0.9553 - val_loss: 0.1095\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1026 - val_accuracy: 0.9534 - val_loss: 0.1279\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9723 - loss: 0.0718 - val_accuracy: 0.9466 - val_loss: 0.1300\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9736 - loss: 0.0697 - val_accuracy: 0.9762 - val_loss: 0.0770\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.0619 - val_accuracy: 0.9733 - val_loss: 0.0766\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.0555 - val_accuracy: 0.9670 - val_loss: 0.1062\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9738 - loss: 0.0807 - val_accuracy: 0.9714 - val_loss: 0.0667\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9822 - loss: 0.0449 - val_accuracy: 0.9777 - val_loss: 0.0516\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0259 - val_accuracy: 0.9714 - val_loss: 0.0690\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.0412 - val_accuracy: 0.9811 - val_loss: 0.0616\n",
            "Dropout Model Validation Accuracy: 0.9781553149223328\n",
            "No Dropout Model Validation Accuracy: 0.981067955493927\n",
            "Testing configuration: Dropout Rate - 0.2, Learning Rate - 0.005\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7095 - loss: 0.8194 - val_accuracy: 0.9136 - val_loss: 0.2472\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9134 - loss: 0.2377 - val_accuracy: 0.9422 - val_loss: 0.1785\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9388 - loss: 0.1671 - val_accuracy: 0.9519 - val_loss: 0.1213\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9511 - loss: 0.1276 - val_accuracy: 0.9665 - val_loss: 0.1073\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9528 - loss: 0.1314 - val_accuracy: 0.9568 - val_loss: 0.1347\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9532 - loss: 0.1373 - val_accuracy: 0.9641 - val_loss: 0.0899\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9602 - loss: 0.1213 - val_accuracy: 0.9660 - val_loss: 0.1025\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9540 - loss: 0.1311 - val_accuracy: 0.9578 - val_loss: 0.1140\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9690 - loss: 0.0934 - val_accuracy: 0.9510 - val_loss: 0.1193\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9522 - loss: 0.1477 - val_accuracy: 0.9650 - val_loss: 0.0875\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8091 - loss: 0.4819 - val_accuracy: 0.9267 - val_loss: 0.2048\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9557 - loss: 0.1137 - val_accuracy: 0.9597 - val_loss: 0.1206\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9622 - loss: 0.1090 - val_accuracy: 0.9534 - val_loss: 0.1284\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9709 - loss: 0.0805 - val_accuracy: 0.9583 - val_loss: 0.1330\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9776 - loss: 0.0600 - val_accuracy: 0.9694 - val_loss: 0.0816\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.0507 - val_accuracy: 0.9476 - val_loss: 0.1900\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9715 - loss: 0.0826 - val_accuracy: 0.9748 - val_loss: 0.0807\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.0569 - val_accuracy: 0.9723 - val_loss: 0.0736\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9790 - loss: 0.0683 - val_accuracy: 0.9757 - val_loss: 0.0618\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9874 - loss: 0.0336 - val_accuracy: 0.9772 - val_loss: 0.0618\n",
            "Dropout Model Validation Accuracy: 0.9650485515594482\n",
            "No Dropout Model Validation Accuracy: 0.9771844744682312\n",
            "Testing configuration: Dropout Rate - 0.3, Learning Rate - 0.001\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5697 - loss: 1.0733 - val_accuracy: 0.9417 - val_loss: 0.1823\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8790 - loss: 0.3085 - val_accuracy: 0.9524 - val_loss: 0.1158\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9359 - loss: 0.1842 - val_accuracy: 0.9621 - val_loss: 0.1003\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9467 - loss: 0.1514 - val_accuracy: 0.9607 - val_loss: 0.1094\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9595 - loss: 0.1185 - val_accuracy: 0.9617 - val_loss: 0.1018\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9567 - loss: 0.1176 - val_accuracy: 0.9709 - val_loss: 0.0778\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9548 - loss: 0.1205 - val_accuracy: 0.9675 - val_loss: 0.0812\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9639 - loss: 0.0978 - val_accuracy: 0.9738 - val_loss: 0.0664\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9678 - loss: 0.0873 - val_accuracy: 0.9704 - val_loss: 0.0746\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9715 - loss: 0.0893 - val_accuracy: 0.9762 - val_loss: 0.0686\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7982 - loss: 0.5102 - val_accuracy: 0.9549 - val_loss: 0.1239\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.0924 - val_accuracy: 0.9621 - val_loss: 0.1009\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9692 - loss: 0.0809 - val_accuracy: 0.9684 - val_loss: 0.0792\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9751 - loss: 0.0582 - val_accuracy: 0.9718 - val_loss: 0.0716\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9849 - loss: 0.0423 - val_accuracy: 0.9752 - val_loss: 0.0656\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9836 - loss: 0.0421 - val_accuracy: 0.9607 - val_loss: 0.0997\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9816 - loss: 0.0449 - val_accuracy: 0.9757 - val_loss: 0.0570\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0277 - val_accuracy: 0.9791 - val_loss: 0.0503\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0200 - val_accuracy: 0.9830 - val_loss: 0.0467\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0244 - val_accuracy: 0.9825 - val_loss: 0.0590\n",
            "Dropout Model Validation Accuracy: 0.9762135744094849\n",
            "No Dropout Model Validation Accuracy: 0.9825242757797241\n",
            "Testing configuration: Dropout Rate - 0.3, Learning Rate - 0.002\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6481 - loss: 0.9335 - val_accuracy: 0.9403 - val_loss: 0.1602\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9031 - loss: 0.2699 - val_accuracy: 0.9383 - val_loss: 0.1479\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9340 - loss: 0.1891 - val_accuracy: 0.9641 - val_loss: 0.0968\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9439 - loss: 0.1700 - val_accuracy: 0.9466 - val_loss: 0.1474\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9486 - loss: 0.1316 - val_accuracy: 0.9573 - val_loss: 0.1035\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9559 - loss: 0.1220 - val_accuracy: 0.9617 - val_loss: 0.1015\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9628 - loss: 0.1043 - val_accuracy: 0.9680 - val_loss: 0.0847\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9591 - loss: 0.1164 - val_accuracy: 0.9694 - val_loss: 0.0670\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9643 - loss: 0.1014 - val_accuracy: 0.9743 - val_loss: 0.0678\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9693 - loss: 0.0857 - val_accuracy: 0.9743 - val_loss: 0.0656\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8399 - loss: 0.4017 - val_accuracy: 0.9612 - val_loss: 0.1031\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9616 - loss: 0.0988 - val_accuracy: 0.9607 - val_loss: 0.0901\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9708 - loss: 0.0865 - val_accuracy: 0.9709 - val_loss: 0.0768\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9702 - loss: 0.0698 - val_accuracy: 0.9680 - val_loss: 0.0858\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9776 - loss: 0.0585 - val_accuracy: 0.9694 - val_loss: 0.0875\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9784 - loss: 0.0580 - val_accuracy: 0.9650 - val_loss: 0.0986\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9789 - loss: 0.0528 - val_accuracy: 0.9772 - val_loss: 0.0549\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0284 - val_accuracy: 0.9816 - val_loss: 0.0534\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9880 - loss: 0.0286 - val_accuracy: 0.9767 - val_loss: 0.0656\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0210 - val_accuracy: 0.9820 - val_loss: 0.0561\n",
            "Dropout Model Validation Accuracy: 0.974271833896637\n",
            "No Dropout Model Validation Accuracy: 0.9820388555526733\n",
            "Testing configuration: Dropout Rate - 0.3, Learning Rate - 0.005\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6436 - loss: 1.0204 - val_accuracy: 0.9432 - val_loss: 0.1695\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9051 - loss: 0.2723 - val_accuracy: 0.9573 - val_loss: 0.1182\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9274 - loss: 0.2189 - val_accuracy: 0.9306 - val_loss: 0.1926\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9404 - loss: 0.1785 - val_accuracy: 0.9563 - val_loss: 0.1176\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.1648 - val_accuracy: 0.9583 - val_loss: 0.1250\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9506 - loss: 0.1511 - val_accuracy: 0.9544 - val_loss: 0.1439\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9528 - loss: 0.1484 - val_accuracy: 0.9587 - val_loss: 0.1146\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9617 - loss: 0.1153 - val_accuracy: 0.9646 - val_loss: 0.1406\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9543 - loss: 0.1614 - val_accuracy: 0.9699 - val_loss: 0.1219\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9657 - loss: 0.1054 - val_accuracy: 0.9592 - val_loss: 0.1449\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8133 - loss: 0.4620 - val_accuracy: 0.9354 - val_loss: 0.1909\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9564 - loss: 0.1212 - val_accuracy: 0.9529 - val_loss: 0.1372\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1275 - val_accuracy: 0.9646 - val_loss: 0.1002\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1015 - val_accuracy: 0.9636 - val_loss: 0.1044\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9728 - loss: 0.0717 - val_accuracy: 0.9573 - val_loss: 0.1280\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9738 - loss: 0.0718 - val_accuracy: 0.9636 - val_loss: 0.0947\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.0623 - val_accuracy: 0.9461 - val_loss: 0.1938\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9700 - loss: 0.0841 - val_accuracy: 0.9655 - val_loss: 0.1084\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0496 - val_accuracy: 0.9767 - val_loss: 0.0760\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9803 - loss: 0.0493 - val_accuracy: 0.9791 - val_loss: 0.0618\n",
            "Dropout Model Validation Accuracy: 0.9592233300209045\n",
            "No Dropout Model Validation Accuracy: 0.9791262149810791\n",
            "Testing configuration: Dropout Rate - 0.4, Learning Rate - 0.001\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4654 - loss: 1.4232 - val_accuracy: 0.9058 - val_loss: 0.2587\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8170 - loss: 0.4682 - val_accuracy: 0.9447 - val_loss: 0.1548\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8822 - loss: 0.3092 - val_accuracy: 0.9592 - val_loss: 0.1192\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9178 - loss: 0.2246 - val_accuracy: 0.9631 - val_loss: 0.1090\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9319 - loss: 0.1853 - val_accuracy: 0.9655 - val_loss: 0.0995\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9382 - loss: 0.1738 - val_accuracy: 0.9650 - val_loss: 0.0900\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.1627 - val_accuracy: 0.9646 - val_loss: 0.0888\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9551 - loss: 0.1245 - val_accuracy: 0.9650 - val_loss: 0.0855\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9538 - loss: 0.1253 - val_accuracy: 0.9646 - val_loss: 0.1025\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9526 - loss: 0.1416 - val_accuracy: 0.9723 - val_loss: 0.0714\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7984 - loss: 0.5231 - val_accuracy: 0.9539 - val_loss: 0.1072\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1059 - val_accuracy: 0.9689 - val_loss: 0.0753\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9720 - loss: 0.0710 - val_accuracy: 0.9617 - val_loss: 0.1098\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9786 - loss: 0.0558 - val_accuracy: 0.9738 - val_loss: 0.0708\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9797 - loss: 0.0525 - val_accuracy: 0.9466 - val_loss: 0.1639\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9824 - loss: 0.0413 - val_accuracy: 0.9573 - val_loss: 0.1122\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9874 - loss: 0.0358 - val_accuracy: 0.9796 - val_loss: 0.0529\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9882 - loss: 0.0334 - val_accuracy: 0.9689 - val_loss: 0.0781\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0252 - val_accuracy: 0.9757 - val_loss: 0.0642\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9845 - loss: 0.0344 - val_accuracy: 0.9689 - val_loss: 0.0970\n",
            "Dropout Model Validation Accuracy: 0.9723300933837891\n",
            "No Dropout Model Validation Accuracy: 0.968932032585144\n",
            "Testing configuration: Dropout Rate - 0.4, Learning Rate - 0.002\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5000 - loss: 1.2809 - val_accuracy: 0.8951 - val_loss: 0.2678\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8416 - loss: 0.3720 - val_accuracy: 0.9374 - val_loss: 0.1795\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8916 - loss: 0.2969 - val_accuracy: 0.9583 - val_loss: 0.1237\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9254 - loss: 0.2079 - val_accuracy: 0.9544 - val_loss: 0.1142\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9417 - loss: 0.1649 - val_accuracy: 0.9617 - val_loss: 0.1084\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9421 - loss: 0.1811 - val_accuracy: 0.9539 - val_loss: 0.1287\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9435 - loss: 0.1654 - val_accuracy: 0.9689 - val_loss: 0.0712\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9567 - loss: 0.1287 - val_accuracy: 0.9689 - val_loss: 0.0860\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9571 - loss: 0.1346 - val_accuracy: 0.9684 - val_loss: 0.0919\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9549 - loss: 0.1252 - val_accuracy: 0.9617 - val_loss: 0.1053\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8297 - loss: 0.4280 - val_accuracy: 0.9524 - val_loss: 0.1171\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.0968 - val_accuracy: 0.9369 - val_loss: 0.1892\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.0989 - val_accuracy: 0.9646 - val_loss: 0.0973\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9755 - loss: 0.0609 - val_accuracy: 0.9282 - val_loss: 0.2224\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9756 - loss: 0.0623 - val_accuracy: 0.9262 - val_loss: 0.3061\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9729 - loss: 0.0736 - val_accuracy: 0.9617 - val_loss: 0.0945\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9799 - loss: 0.0594 - val_accuracy: 0.9796 - val_loss: 0.0560\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9819 - loss: 0.0499 - val_accuracy: 0.9772 - val_loss: 0.0644\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0254 - val_accuracy: 0.9820 - val_loss: 0.0452\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9858 - loss: 0.0387 - val_accuracy: 0.9830 - val_loss: 0.0467\n",
            "Dropout Model Validation Accuracy: 0.9616504907608032\n",
            "No Dropout Model Validation Accuracy: 0.9830096960067749\n",
            "Testing configuration: Dropout Rate - 0.4, Learning Rate - 0.005\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5340 - loss: 1.2321 - val_accuracy: 0.8029 - val_loss: 0.3172\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7824 - loss: 0.4702 - val_accuracy: 0.8932 - val_loss: 0.2838\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8227 - loss: 0.4025 - val_accuracy: 0.8689 - val_loss: 0.2250\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8831 - loss: 0.3066 - val_accuracy: 0.9359 - val_loss: 0.1902\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9008 - loss: 0.2861 - val_accuracy: 0.9563 - val_loss: 0.1195\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9272 - loss: 0.2206 - val_accuracy: 0.9583 - val_loss: 0.1261\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9274 - loss: 0.2102 - val_accuracy: 0.9689 - val_loss: 0.1105\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9258 - loss: 0.2291 - val_accuracy: 0.9524 - val_loss: 0.1118\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9356 - loss: 0.1939 - val_accuracy: 0.9636 - val_loss: 0.1103\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9282 - loss: 0.2143 - val_accuracy: 0.9578 - val_loss: 0.0971\n",
            "Epoch 1/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8203 - loss: 0.4549 - val_accuracy: 0.9277 - val_loss: 0.1779\n",
            "Epoch 2/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1215 - val_accuracy: 0.9607 - val_loss: 0.1087\n",
            "Epoch 3/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.1076 - val_accuracy: 0.9374 - val_loss: 0.1546\n",
            "Epoch 4/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9701 - loss: 0.0835 - val_accuracy: 0.9733 - val_loss: 0.0751\n",
            "Epoch 5/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9785 - loss: 0.0579 - val_accuracy: 0.9675 - val_loss: 0.0861\n",
            "Epoch 6/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9755 - loss: 0.0604 - val_accuracy: 0.9718 - val_loss: 0.0667\n",
            "Epoch 7/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.0494 - val_accuracy: 0.9549 - val_loss: 0.1404\n",
            "Epoch 8/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9701 - loss: 0.1015 - val_accuracy: 0.9655 - val_loss: 0.1051\n",
            "Epoch 9/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9790 - loss: 0.0565 - val_accuracy: 0.9607 - val_loss: 0.1258\n",
            "Epoch 10/10\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9775 - loss: 0.0687 - val_accuracy: 0.9748 - val_loss: 0.0730\n",
            "Dropout Model Validation Accuracy: 0.9577670097351074\n",
            "No Dropout Model Validation Accuracy: 0.9747572541236877\n",
            "Best Model Configuration: {'dropout_rate': 0.4, 'learning_rate': 0.002, 'type': 'nodropout'}\n",
            "Best Dropout Model Validation Accuracy: 0.9781553149223328\n",
            "Best No Dropout Model Validation Accuracy: 0.9830096960067749\n"
          ]
        }
      ],
      "source": [
        "# IMPORT LIBRARIES\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Define paths to the training and test datasets\n",
        "train_data_path = 'X_train.txt'\n",
        "train_labels_path = 'y_train.txt'\n",
        "test_data_path = 'X_test.txt'\n",
        "test_labels_path = 'y_test.txt'\n",
        "\n",
        "# Load train and test datasets\n",
        "X_train = pd.read_csv(train_data_path, sep='\\s+', header=None)\n",
        "y_train = pd.read_csv(train_labels_path, sep='\\s+', header=None)\n",
        "X_test = pd.read_csv(test_data_path, sep='\\s+', header=None)\n",
        "y_test = pd.read_csv(test_labels_path, sep='\\s+', header=None)\n",
        "\n",
        "# Combine training and testing data\n",
        "X = pd.concat([X_train, X_test], axis=0)\n",
        "y = pd.concat([y_train, y_test], axis=0)\n",
        "\n",
        "# One-hot encode the labels since this is a classification task\n",
        "encoder = OneHotEncoder(sparse_output=False)  # Updated argument name\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "# Create networks with dropout and without dropout\n",
        "def create_activity_dropout_and_nodropout_networks(n_inputs: int, n_outputs: int, dropout_rate: float = 0.3, learning_rate: float = 0.001):\n",
        "    \"\"\"Creates one neural network with dropout applied after each layer, and\n",
        "    one neural network without dropout.\n",
        "    \"\"\"\n",
        "    # Network with Dropout\n",
        "    dropout_input = keras.Input(shape=(n_inputs,))\n",
        "    dropout_hidden = keras.layers.Dense(128, activation='relu')(dropout_input)\n",
        "    dropout_hidden = keras.layers.Dropout(dropout_rate)(dropout_hidden)\n",
        "    dropout_hidden = keras.layers.Dense(64, activation='relu')(dropout_hidden)\n",
        "    dropout_hidden = keras.layers.Dropout(dropout_rate)(dropout_hidden)\n",
        "    dropout_hidden = keras.layers.Dense(32, activation='relu')(dropout_hidden)\n",
        "    dropout_hidden = keras.layers.Dropout(dropout_rate)(dropout_hidden)\n",
        "    dropout_output = keras.layers.Dense(n_outputs, activation='softmax')(dropout_hidden)\n",
        "    dropout_model = keras.Model(dropout_input, dropout_output)\n",
        "\n",
        "    # Network without Dropout\n",
        "    nodropout_input = keras.Input(shape=(n_inputs,))\n",
        "    nodropout_hidden = keras.layers.Dense(128, activation='relu')(nodropout_input)\n",
        "    nodropout_hidden = keras.layers.Dense(64, activation='relu')(nodropout_hidden)\n",
        "    nodropout_hidden = keras.layers.Dense(32, activation='relu')(nodropout_hidden)\n",
        "    nodropout_output = keras.layers.Dense(n_outputs, activation='softmax')(nodropout_hidden)\n",
        "    nodropout_model = keras.Model(nodropout_input, nodropout_output)\n",
        "\n",
        "    # Compile both models with specified learning rate\n",
        "    dropout_optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    nodropout_optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    loss = 'categorical_crossentropy'\n",
        "\n",
        "    dropout_model.compile(optimizer=dropout_optimizer, loss=loss, metrics=['accuracy'])\n",
        "    nodropout_model.compile(optimizer=nodropout_optimizer, loss=loss, metrics=['accuracy'])\n",
        "\n",
        "    return dropout_model, nodropout_model\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "def hyperparameter_tuning(n_inputs: int, n_outputs: int, X_train, y_train, X_val, y_val):\n",
        "    \"\"\"Test different variations of hyperparameters for the dropout and no-dropout networks.\"\"\"\n",
        "\n",
        "    # Define hyperparameter sets\n",
        "    dropout_rates = [0.2, 0.3, 0.4]\n",
        "    learning_rates = [0.001, 0.002, 0.005]\n",
        "\n",
        "    best_dropout_model = None\n",
        "    best_nodropout_model = None\n",
        "    best_dropout_val_acc = 0\n",
        "    best_nodropout_val_acc = 0\n",
        "    best_params = None\n",
        "\n",
        "    # Loop through the hyperparameter sets\n",
        "    for dropout_rate in dropout_rates:\n",
        "        for learning_rate in learning_rates:\n",
        "            print(f\"Testing configuration: Dropout Rate - {dropout_rate}, Learning Rate - {learning_rate}\")\n",
        "\n",
        "            # Create the dropout and no-dropout models for the current configuration\n",
        "            dropout_model, nodropout_model = create_activity_dropout_and_nodropout_networks(n_inputs, n_outputs, dropout_rate, learning_rate)\n",
        "\n",
        "            # Train both models\n",
        "            dropout_model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), verbose=1)\n",
        "            nodropout_model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "            # Evaluate the models on the validation data\n",
        "            dropout_val_loss, dropout_val_acc = dropout_model.evaluate(X_val, y_val, verbose=0)\n",
        "            nodropout_val_loss, nodropout_val_acc = nodropout_model.evaluate(X_val, y_val, verbose=0)\n",
        "\n",
        "            print(f\"Dropout Model Validation Accuracy: {dropout_val_acc}\")\n",
        "            print(f\"No Dropout Model Validation Accuracy: {nodropout_val_acc}\")\n",
        "\n",
        "            # Update the best model if this configuration is better\n",
        "            if dropout_val_acc > best_dropout_val_acc:\n",
        "                best_dropout_model = dropout_model\n",
        "                best_dropout_val_acc = dropout_val_acc\n",
        "                best_params = {'dropout_rate': dropout_rate, 'learning_rate': learning_rate, 'type': 'dropout'}\n",
        "\n",
        "            if nodropout_val_acc > best_nodropout_val_acc:\n",
        "                best_nodropout_model = nodropout_model\n",
        "                best_nodropout_val_acc = nodropout_val_acc\n",
        "                best_params = {'dropout_rate': dropout_rate, 'learning_rate': learning_rate, 'type': 'nodropout'}\n",
        "\n",
        "    # Print the best configuration and its validation accuracy\n",
        "    print(f\"Best Model Configuration: {best_params}\")\n",
        "    print(f\"Best Dropout Model Validation Accuracy: {best_dropout_val_acc}\")\n",
        "    print(f\"Best No Dropout Model Validation Accuracy: {best_nodropout_val_acc}\")\n",
        "\n",
        "    return best_dropout_model, best_nodropout_model\n",
        "\n",
        "# Use the number of features from the dataset\n",
        "n_inputs = X_train.shape[1]\n",
        "n_outputs = y_train.shape[1]  # Number of activity types (6 in this case)\n",
        "\n",
        "# Run hyperparameter tuning on the dataset\n",
        "best_dropout_model, best_nodropout_model = hyperparameter_tuning(n_inputs, n_outputs, X_train, y_train, X_val, y_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V9FQ_nvVIyGw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}